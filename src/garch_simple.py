#!/usr/bin/env python3
"""
GARCH(1,1) Model Implementation and Evaluation

This script implements a GARCH(1,1) model for volatility modeling and evaluation.
It serves as a classical baseline for comparison with modern generative models.

Author: Simin Ali
Thesis: Diffusion Models in Generative AI for Financial Data Synthesis and Risk Management
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy import stats
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.stattools import adfuller
import warnings
warnings.filterwarnings('ignore')

def load_and_prepare_data():
    """Load and prepare S&P 500 data."""
    print("ðŸ“Š Loading S&P 500 data...")
    
    # Load data from data folder
    data = pd.read_csv("../data/sp500_data.csv", index_col=0, parse_dates=True)
    # Remove the header row if it exists
    if data.index[0] == 'Ticker':
        data = data.iloc[1:]
    data.index = pd.to_datetime(data.index)
    data['Close'] = pd.to_numeric(data['Close'], errors='coerce')
    data = data[['Close']]
    
    # Compute log returns
    data['Log_Returns'] = np.log(data['Close'] / data['Close'].shift(1))
    data = data.dropna()
    
    print(f"âœ… Data loaded: {len(data)} observations")
    print(f"   Date range: {data.index.min()} to {data.index.max()}")
    
    return data

def split_data(data):
    """Split data into training and testing sets."""
    returns = data['Log_Returns'].dropna()
    
    # Split 80/20 without shuffling to preserve time order
    split_idx = int(len(returns) * 0.8)
    train_returns = returns[:split_idx]
    test_returns = returns[split_idx:]
    
    print(f"ðŸ“ˆ Data split:")
    print(f"   Training: {len(train_returns)} observations")
    print(f"   Testing: {len(test_returns)} observations")
    
    return train_returns, test_returns

def fit_garch_model(train_returns):
    """Fit GARCH(1,1) model using ARIMA-GARCH approach."""
    print("ðŸ”§ Fitting GARCH(1,1) model...")
    
    # Simple GARCH(1,1) implementation using ARIMA residuals
    # This is a simplified version - in practice you might use arch library
    
    # Fit ARIMA model to get residuals
    model = ARIMA(train_returns, order=(1, 0, 1))
    fitted_model = model.fit()
    residuals = fitted_model.resid
    
    # Estimate GARCH parameters (simplified)
    # In practice, use proper GARCH estimation
    alpha = 0.1  # ARCH parameter
    beta = 0.8   # GARCH parameter
    omega = np.var(residuals) * (1 - alpha - beta)  # Constant
    
    print(f"âœ… GARCH(1,1) parameters estimated:")
    print(f"   Ï‰ (constant): {omega:.6f}")
    print(f"   Î± (ARCH): {alpha:.3f}")
    print(f"   Î² (GARCH): {beta:.3f}")
    
    return fitted_model, (omega, alpha, beta)

def generate_garch_forecasts(model, params, test_returns):
    """Generate GARCH forecasts for VaR calculation."""
    print("ðŸ“Š Generating GARCH forecasts...")
    
    omega, alpha, beta = params
    forecasts = []
    
    # Use last training volatility as starting point
    last_vol = np.std(model.resid)
    
    for i in range(len(test_returns)):
        # GARCH(1,1) volatility forecast
        vol_forecast = np.sqrt(omega + alpha * last_vol**2 + beta * last_vol**2)
        forecasts.append(vol_forecast)
        last_vol = vol_forecast
    
    # Calculate VaR forecasts (assuming normal distribution)
    var_forecasts = -1.645 * np.array(forecasts)  # 5% VaR
    
    print(f"âœ… Generated {len(forecasts)} volatility forecasts")
    
    return np.array(forecasts), np.array(var_forecasts)

def evaluate_garch_performance(test_returns, var_forecasts):
    """Evaluate GARCH model performance."""
    print("ðŸ“ˆ Evaluating GARCH performance...")
    
    # Calculate violations
    violations = test_returns < var_forecasts
    n_violations = np.sum(violations)
    violation_rate = n_violations / len(test_returns)
    
    # Basic statistics
    stats_dict = {
        'Total_Observations': len(test_returns),
        'Violations': n_violations,
        'Violation_Rate': violation_rate,
        'Expected_Rate': 0.05,
        'Mean_Return': np.mean(test_returns),
        'Std_Return': np.std(test_returns),
        'Skewness': stats.skew(test_returns),
        'Kurtosis': stats.kurtosis(test_returns)
    }
    
    print(f"âœ… GARCH Evaluation Results:")
    print(f"   Violations: {n_violations}/{len(test_returns)} ({violation_rate:.3f})")
    print(f"   Expected rate: 0.05")
    print(f"   Mean return: {stats_dict['Mean_Return']:.6f}")
    print(f"   Std return: {stats_dict['Std_Return']:.6f}")
    
    return stats_dict, violations

def save_results(test_returns, var_forecasts, stats_dict):
    """Save results for comprehensive evaluation."""
    print("ðŸ’¾ Saving GARCH results...")
    
    # Save returns and forecasts
    np.save("../results/garch_returns.npy", test_returns.values)
    np.save("../results/garch_var_forecasts.npy", var_forecasts)
    
    # Save statistics
    import json
    # Convert numpy types to native Python types for JSON serialization
    json_stats = {}
    for key, value in stats_dict.items():
        if isinstance(value, (np.integer, np.floating)):
            json_stats[key] = float(value)
        else:
            json_stats[key] = value
    
    with open("../results/garch_evaluation/garch_stats.json", 'w') as f:
        json.dump(json_stats, f, indent=2)
    
    print("âœ… GARCH results saved to results/ directory")

def create_plots(data, test_returns, var_forecasts, violations):
    """Create evaluation plots."""
    print("ðŸ“Š Creating GARCH evaluation plots...")
    
    # Create results directory
    import os
    os.makedirs("../results/garch_evaluation/plots", exist_ok=True)
    
    # Plot 1: Returns and VaR
    plt.figure(figsize=(12, 6))
    plt.plot(test_returns.index, test_returns.values, label='Returns', alpha=0.7)
    plt.plot(test_returns.index, var_forecasts, label='VaR Forecast', color='red')
    plt.scatter(test_returns.index[violations], test_returns.values[violations], 
               color='red', s=20, label='VaR Violations', zorder=5)
    plt.title('GARCH(1,1) VaR Forecasts and Violations')
    plt.xlabel('Date')
    plt.ylabel('Returns')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig("../results/garch_evaluation/plots/garch_var_forecasts.pdf", dpi=300, bbox_inches='tight')
    plt.savefig("../results/garch_evaluation/plots/garch_var_forecasts.png", dpi=300, bbox_inches='tight')
    plt.close()
    
    # Plot 2: Returns distribution
    plt.figure(figsize=(10, 6))
    plt.hist(test_returns.values, bins=50, density=True, alpha=0.7, label='Returns')
    plt.axvline(np.mean(test_returns), color='red', linestyle='--', label='Mean')
    plt.title('GARCH Model: Returns Distribution')
    plt.xlabel('Returns')
    plt.ylabel('Density')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig("../results/garch_evaluation/plots/garch_returns_distribution.pdf", dpi=300, bbox_inches='tight')
    plt.savefig("../results/garch_evaluation/plots/garch_returns_distribution.png", dpi=300, bbox_inches='tight')
    plt.close()
    
    print("âœ… GARCH plots saved to results/garch_evaluation/plots/")

def main():
    """Main function to run GARCH evaluation."""
    print("ðŸŽ“ GARCH(1,1) Model Evaluation")
    print("=" * 50)
    
    try:
        # Load and prepare data
        data = load_and_prepare_data()
        
        # Split data
        train_returns, test_returns = split_data(data)
        
        # Fit GARCH model
        model, params = fit_garch_model(train_returns)
        
        # Generate forecasts
        vol_forecasts, var_forecasts = generate_garch_forecasts(model, params, test_returns)
        
        # Evaluate performance
        stats_dict, violations = evaluate_garch_performance(test_returns, var_forecasts)
        
        # Save results
        save_results(test_returns, var_forecasts, stats_dict)
        
        # Create plots
        create_plots(data, test_returns, var_forecasts, violations)
        
        print("\nðŸŽ‰ GARCH evaluation completed successfully!")
        print("ðŸ“ Results saved in: results/garch_evaluation/")
        
    except Exception as e:
        print(f"âŒ Error in GARCH evaluation: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
